{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "\n",
    "import gensim.downloader as api\n",
    "\n",
    "def replace_invalid_with_nan(vector):\n",
    "    return np.where(vector==0.0, np.nan, vector)\n",
    "\n",
    "def glove_vector(words, wv):\n",
    "    return wv.get_mean_vector(words)\n",
    "\n",
    "def add_cn_prefix(word):\n",
    "    return f'/c/en/{word}'\n",
    "\n",
    "def cn_vector(words, wv):\n",
    "    if len(words) > 1:\n",
    "        compound = add_cn_prefix('_'.join(words))\n",
    "        if wv.__contains__(compound):\n",
    "            return wv.get_mean_vector([compound])\n",
    "    return wv.get_mean_vector([add_cn_prefix(word) for word in words])\n",
    "    \n",
    "def get_static_embed(word, wv, mode):\n",
    "    words = word.split()\n",
    "    if mode=='glove':\n",
    "        vector = glove_vector(words, wv)\n",
    "    elif mode=='cn':\n",
    "        vector = cn_vector(words, wv)\n",
    "    \n",
    "    if all(vector == 0.0):\n",
    "        return replace_invalid_with_nan(vector)\n",
    "    return vector\n",
    "\n",
    "def unpack_anns(list_of_annotations):\n",
    "    return [(i, x['whole']['wholeAnnotation']) for i, x in enumerate(list_of_annotations)]\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = osp.abspath('../collected_data/')\n",
    "processed_dir = osp.join(input_dir, 'processed')\n",
    "kilogram_dir = osp.abspath('../kilogram')\n",
    "\n",
    "output_dir = osp.join(processed_dir, 'static_encodings')\n",
    "if not osp.isdir(output_dir):\n",
    "    print(f'make directory {output_dir}')\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(s): \n",
    "    return s.strip().lower()\n",
    "\n",
    "def clean_raw_ann(s):\n",
    "    s = re.sub(r'[^a-zA-Z0-9 ]', '', s)\n",
    "    return s.strip().lower()\n",
    "\n",
    "input_file = osp.join(processed_dir, 'final_processed_data.csv')\n",
    "\n",
    "ann_df = pd.read_csv(input_file, index_col=0)\n",
    "\n",
    "ann_df.raw_annotation = ann_df.raw_annotation.map(clean_raw_ann)\n",
    "ann_df.clean_annotation = ann_df.clean_annotation.map(clean_str)\n",
    "ann_df.head_noun = ann_df.head_noun.map(clean_str)\n",
    "\n",
    "tangrams = sorted(pd.unique(ann_df.tangram))\n",
    "scenes = sorted(pd.unique(ann_df.scene))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leave out raw and clean anns\n",
    "\n",
    "for model, model_name in [\n",
    "        ('glove-wiki-gigaword-300', 'glove'),\n",
    "        ('conceptnet-numberbatch-17-06-300', 'cn')\n",
    "    ]:\n",
    "    \n",
    "    print(f'load embeddings for {model_name} / {model}')\n",
    "    word_vectors = api.load(model)\n",
    "    def get_embeddings(word):\n",
    "        return get_static_embed(word, wv=word_vectors, mode=model_name)\n",
    "\n",
    "    print('calculate ann embeddings')\n",
    "    ann_idx_array = ann_df[['item_identifyer', 'tangram', 'scene']].values\n",
    "\n",
    "    head_embeds_series = ann_df['head_noun'].progress_map(get_embeddings)\n",
    "    head_embeds = np.stack(head_embeds_series.to_list())\n",
    "\n",
    "    wn_embeds_series = ann_df['wn_lemma'].progress_map(get_embeddings)\n",
    "    wn_embeds = np.stack(wn_embeds_series.to_list())\n",
    "\n",
    "    outfile = osp.join(output_dir, f'./ann_{model_name}_embeddings.npz')\n",
    "    print(f'write to file: {outfile}')\n",
    "    np.savez(outfile, text_idx=ann_idx_array, text_head_emb=head_embeds, text_wn_emb=wn_embeds)\n",
    "    \n",
    "    \n",
    "    print('calculate tangram embeddings')\n",
    "    for split in 'dense', 'dense10':\n",
    "        print(f'extracting features for {split} split')\n",
    "\n",
    "        kilogram_path = osp.join(kilogram_dir, 'dataset', f'{split}.json')\n",
    "        kilogram_df = pd.read_json(kilogram_path).T\n",
    "\n",
    "        kilogram_df = kilogram_df.loc[tangrams]\n",
    "        kilogram_df['annotation_tuples'] = kilogram_df.annotations.map(unpack_anns)\n",
    "\n",
    "        exploded_kilogram_df = kilogram_df.explode('annotation_tuples')\n",
    "        exploded_kilogram_df['ann_idx'] = exploded_kilogram_df.annotation_tuples.map(lambda x: x[0])\n",
    "        exploded_kilogram_df['ann'] = exploded_kilogram_df.annotation_tuples.map(lambda x: x[1])\n",
    "\n",
    "        exploded_kilogram_df['item_identifyer'] = exploded_kilogram_df.apply(lambda x: f'{x.name}_{x.ann_idx}', axis=1)\n",
    "        exploded_kilogram_df = exploded_kilogram_df.reset_index().rename(columns={'index': 'tangram'})\n",
    "\n",
    "        # extract features\n",
    "\n",
    "        kg_idx_array = exploded_kilogram_df[['item_identifyer', 'tangram', 'ann_idx']].values\n",
    "\n",
    "        embeds_series = exploded_kilogram_df['ann'].progress_map(get_embeddings)\n",
    "        embeds = np.stack(embeds_series.to_list())\n",
    "\n",
    "        outfile = osp.join(output_dir, f'./{split}_{model_name}_embeddings.npz')\n",
    "        print(f'write to file: {outfile}')\n",
    "        np.savez(outfile, text_idx=kg_idx_array, text_emb=embeds)\n",
    "        \n",
    "    print('calculate scene category embeddings')\n",
    "    sc_idx_array = np.array(scenes)\n",
    "    embeds_list = [get_embeddings(s.replace('_', ' ')) for s in sc_idx_array]\n",
    "    embeds = np.stack(embeds_list)\n",
    "\n",
    "    outfile = osp.join(output_dir, f'./scene_{model_name}_embeddings.npz')\n",
    "    print(f'write to file: {outfile}')\n",
    "    np.savez(outfile, img_idx=sc_idx_array, img_emb=embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gensim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
