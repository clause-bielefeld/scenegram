{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path as osp\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_slice = '0_0'\n",
    "input_base = '../generated_data/experiment_slices/results'\n",
    "input_dir = osp.join(input_base, input_slice)\n",
    "input_file = osp.join(input_dir, 'collected_annotations.csv')\n",
    "output_base = '../collected_data/intermediate/head_noun_extraction'\n",
    "output_dir = osp.join(output_base, input_slice)\n",
    "if not osp.isdir(output_dir):\n",
    "    print(f'create dir {output_dir}')\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_conjunctions(s, spacy_model):\n",
    "    doc = spacy_model(s)\n",
    "\n",
    "    for token in doc:\n",
    "        if token.dep_ == 'cc':\n",
    "            conjunction = token\n",
    "            s = doc[:conjunction.i].text\n",
    "            break\n",
    "        \n",
    "    return s\n",
    "\n",
    "def clip_initial_article(s, spacy_model, normalize=True):\n",
    "    if normalize:\n",
    "        s = s.lower().strip()\n",
    "    \n",
    "    doc = spacy_model(s)\n",
    "    \n",
    "    serialized = doc.to_json()\n",
    "    tokens = serialized['tokens']\n",
    "    \n",
    "    first_token = tokens[0]\n",
    "    if first_token['pos'] == 'DET':\n",
    "        assert len(tokens) > 1\n",
    "        second_token = tokens[1]\n",
    "        start_idx = second_token['start']\n",
    "        return s[start_idx:]\n",
    "    \n",
    "    return s\n",
    "\n",
    "def get_compounds(token):\n",
    "    \n",
    "    tokens = [token]\n",
    "    for t in token.children:\n",
    "        if t.dep_ == 'compound':\n",
    "            # recursive call\n",
    "            tokens += get_compounds(t)\n",
    "        \n",
    "    return tokens\n",
    "\n",
    "def get_compound_str(token):\n",
    "\n",
    "    compound_tokens = get_compounds(token)\n",
    "    sorted_compound_tokens = sorted(compound_tokens, key=lambda x: x.i)\n",
    "    compound_string = ' '.join([t.text for t in sorted_compound_tokens])\n",
    "    \n",
    "    return compound_string\n",
    "\n",
    "# adapted from kilogram code (+ compounds)\n",
    "\n",
    "def get_np_head(s, spacy_model, normalize=True):# -> Any | None:\n",
    "    \n",
    "    if normalize:\n",
    "        s = s.lower().strip()\n",
    "    \n",
    "    #hard coded fix typo\n",
    "    if s.startswith('aa '):\n",
    "        s=s.replace('aa ', 'a ')\n",
    "    \n",
    "    #get tree\n",
    "    doc = spacy_model(s)\n",
    "    \n",
    "    #single word\n",
    "    if len(doc)==1:\n",
    "        return doc[0]\n",
    "        \n",
    "    np_head = None\n",
    "    for token in doc:\n",
    "        if token.dep_=='ROOT' and token.head.pos_ in ['NOUN', 'INTJ', 'PROPN', 'PRON', 'ADJ', 'ADV']: \n",
    "            np_head = token\n",
    "         \n",
    "        if token.dep_=='ROOT' and token.head.pos_=='VERB':\n",
    "            if list(token.children)[0].dep_=='prep':\n",
    "                np_head = token\n",
    "            else:\n",
    "                np_head = list(token.children)[0]\n",
    "\n",
    "        if token.dep_=='ROOT' and token.head.pos_=='ADP':\n",
    "            np_head = list(token.children)[-1]\n",
    "\n",
    "        # hard code \"xx can\" utterances\n",
    "        if token.dep_=='ROOT' and token.text=='can':\n",
    "            np_head = token\n",
    "            \n",
    "    return np_head\n",
    "\n",
    "def get_head_string(s, spacy_model, normalize=True):\n",
    "    head = get_np_head(s, spacy_model, normalize=normalize)\n",
    "    if head:\n",
    "        return head.text\n",
    "\n",
    "def get_head_compound_string(s, spacy_model, normalize=True):\n",
    "    head = get_np_head(s, spacy_model, normalize=normalize)\n",
    "    if head:\n",
    "        return get_compound_str(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_df = pd.read_csv(input_file, index_col=0)[\n",
    "    ['item_identifyer', 'raw_annotation']\n",
    "]\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_identifyer</th>\n",
       "      <th>raw_annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3-none-bws0_0</td>\n",
       "      <td>A PRIEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3-none-bws0_1</td>\n",
       "      <td>praying person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3-none-bws0_10</td>\n",
       "      <td>a person reading a book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3-none-bws0_2</td>\n",
       "      <td>human in robe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3-none-bws0_3</td>\n",
       "      <td>Pulpit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2547</th>\n",
       "      <td>69-sea_bottom-sws16_15</td>\n",
       "      <td>sea otter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2548</th>\n",
       "      <td>70-bathroom-sws16_15</td>\n",
       "      <td>chair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2549</th>\n",
       "      <td>70-bedroom-sws12_13</td>\n",
       "      <td>TENTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2550</th>\n",
       "      <td>71-office-sws16_15</td>\n",
       "      <td>desk lamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2551</th>\n",
       "      <td>71-street-sws12_13</td>\n",
       "      <td>K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2552 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             item_identifyer           raw_annotation\n",
       "0              3-none-bws0_0                 A PRIEST\n",
       "1              3-none-bws0_1           praying person\n",
       "2             3-none-bws0_10  a person reading a book\n",
       "3              3-none-bws0_2            human in robe\n",
       "4              3-none-bws0_3                   Pulpit\n",
       "...                      ...                      ...\n",
       "2547  69-sea_bottom-sws16_15                sea otter\n",
       "2548    70-bathroom-sws16_15                    chair\n",
       "2549     70-bedroom-sws12_13                    TENTS\n",
       "2550      71-office-sws16_15                desk lamp\n",
       "2551      71-street-sws12_13                        K\n",
       "\n",
       "[2552 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove newline characters and trailing whitespace...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb8d3f2732c4ba3bca85eaeb00d63ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2552 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clipping articles...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd9cf7a3e54a48e297d04ca33ae7c744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2552 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting head nouns (with compounds)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "894a4f36d0754aee95da698e23bb19bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2552 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('remove newline characters and trailing whitespace...')\n",
    "f = lambda x: x.replace('\\n', ' ').strip()\n",
    "ann_df['raw_annotation'] = ann_df.raw_annotation.progress_map(f)\n",
    "\n",
    "print('clipping articles...')\n",
    "f = lambda x: clip_initial_article(x, nlp)\n",
    "ann_df['clean_annotation'] = ann_df.raw_annotation.progress_map(f)\n",
    "\n",
    "# print('extracting head nouns (without compounds)...')\n",
    "# f = lambda x: get_head_string(x, nlp)\n",
    "# ann_df['head_noun'] = ann_df.raw_annotation.progress_map(f)\n",
    "\n",
    "print('extracting head nouns (with compounds)...')\n",
    "f = lambda x: get_head_compound_string(x, nlp)\n",
    "ann_df['head_noun'] = ann_df.raw_annotation.progress_map(f)\n",
    "\n",
    "ann_df['comments'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write df 0 to ../collected_data/intermediate/head_noun_extraction/0_0/collected_annotations_clean_auto_0.csv\n",
      "write df 1 to ../collected_data/intermediate/head_noun_extraction/0_0/collected_annotations_clean_auto_1.csv\n"
     ]
    }
   ],
   "source": [
    "ann_df_0 = ann_df.sample(frac=0.5, random_state=123).sort_index()\n",
    "ann_df_1 = ann_df[\n",
    "    ~ann_df.index.isin(ann_df_0.index)\n",
    "].sort_index()\n",
    "\n",
    "pd.testing.assert_frame_equal(\n",
    "    ann_df,\n",
    "    pd.concat([ann_df_0, ann_df_1]).sort_index()\n",
    ")\n",
    "\n",
    "for i, df in enumerate([ann_df_0, ann_df_1]):\n",
    "    out_path = osp.join(output_dir, f'collected_annotations_clean_auto_{i}.csv')\n",
    "    print(f'write df {i} to {out_path}')\n",
    "    df.to_csv(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1276, 1276)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ann_df_0), len(ann_df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_identifyer</th>\n",
       "      <th>raw_annotation</th>\n",
       "      <th>clean_annotation</th>\n",
       "      <th>head_noun</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3-none-bws0_0</td>\n",
       "      <td>A PRIEST</td>\n",
       "      <td>priest</td>\n",
       "      <td>priest</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3-none-bws0_4</td>\n",
       "      <td>person praying</td>\n",
       "      <td>person praying</td>\n",
       "      <td>person</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3-kitchen-sws6_10</td>\n",
       "      <td>table</td>\n",
       "      <td>table</td>\n",
       "      <td>table</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3-kitchen-sws6_4</td>\n",
       "      <td>knight</td>\n",
       "      <td>knight</td>\n",
       "      <td>knight</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3-bathroom-sws2_0</td>\n",
       "      <td>bathroom attendant</td>\n",
       "      <td>bathroom attendant</td>\n",
       "      <td>bathroom attendant</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_identifyer      raw_annotation    clean_annotation  \\\n",
       "0       3-none-bws0_0            A PRIEST              priest   \n",
       "5       3-none-bws0_4      person praying      person praying   \n",
       "7   3-kitchen-sws6_10               table               table   \n",
       "12   3-kitchen-sws6_4              knight              knight   \n",
       "13  3-bathroom-sws2_0  bathroom attendant  bathroom attendant   \n",
       "\n",
       "             head_noun comments  \n",
       "0               priest           \n",
       "5               person           \n",
       "7                table           \n",
       "12              knight           \n",
       "13  bathroom attendant           "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_df_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_identifyer</th>\n",
       "      <th>raw_annotation</th>\n",
       "      <th>clean_annotation</th>\n",
       "      <th>head_noun</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3-none-bws0_1</td>\n",
       "      <td>praying person</td>\n",
       "      <td>praying person</td>\n",
       "      <td>person</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3-none-bws0_10</td>\n",
       "      <td>a person reading a book</td>\n",
       "      <td>person reading a book</td>\n",
       "      <td>person</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3-none-bws0_2</td>\n",
       "      <td>human in robe</td>\n",
       "      <td>human in robe</td>\n",
       "      <td>human</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3-none-bws0_3</td>\n",
       "      <td>Pulpit</td>\n",
       "      <td>pulpit</td>\n",
       "      <td>pulpit</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3-kitchen-sws6_0</td>\n",
       "      <td>rooms</td>\n",
       "      <td>rooms</td>\n",
       "      <td>rooms</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    item_identifyer           raw_annotation       clean_annotation head_noun  \\\n",
       "1     3-none-bws0_1           praying person         praying person    person   \n",
       "2    3-none-bws0_10  a person reading a book  person reading a book    person   \n",
       "3     3-none-bws0_2            human in robe          human in robe     human   \n",
       "4     3-none-bws0_3                   Pulpit                 pulpit    pulpit   \n",
       "6  3-kitchen-sws6_0                    rooms                  rooms     rooms   \n",
       "\n",
       "  comments  \n",
       "1           \n",
       "2           \n",
       "3           \n",
       "4           \n",
       "6           "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_df_1.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "context_representations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
