{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argilla as rg\n",
    "import pandas as pd\n",
    "import os.path as osp\n",
    "from tqdm.autonotebook import tqdm\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "data_dir = osp.abspath('../generated_data/')\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse credentials\n",
    "with open('argilla_credentials.sh', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    content_lines = [c.strip() for c in lines if \"=\" in c]\n",
    "    credentials = {\n",
    "        l.split('=')[0]: l.split('=')[1] \n",
    "        for l in content_lines\n",
    "    }\n",
    "    \n",
    "    \n",
    "# connect as owner to argilla server\n",
    "rg.init(\n",
    "    api_url=credentials['ARGILLA_API_URL'],\n",
    "    api_key=credentials['OWNER_API_KEY'],\n",
    "    #extra_headers={\"Authorization\": f\"Bearer {os.environ['HF_TOKEN']}\"}\n",
    ")\n",
    "\n",
    "# load data\n",
    "item_path = osp.join(data_dir, 'dense10_items.json')\n",
    "print(f'read items from {item_path} ...')\n",
    "item_df = pd.read_json(item_path).set_index('item_id')\n",
    "\n",
    "# print owner info\n",
    "rg.User.me()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "workspaces = rg.Workspace.list()\n",
    "all_records = []\n",
    "\n",
    "for workspace in tqdm(workspaces):\n",
    "    workspace_datasets = rg.FeedbackDataset.list(workspace=workspace.name)\n",
    "    \n",
    "    annotation_datasets = [wd for wd in workspace_datasets if '02_annotation' in wd.name]\n",
    "    assert len(annotation_datasets) == 1\n",
    "    annotation_dataset = annotation_datasets[0]\n",
    "    \n",
    "    annotation_records = list(annotation_dataset.records)\n",
    "\n",
    "    for record in annotation_records:\n",
    "        all_records.append({**record.metadata, 'n_responses': len(record.responses)})\n",
    "\n",
    "all_records_df = pd.DataFrame(all_records)\n",
    "all_records_df = all_records_df.merge(item_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_range(x):\n",
    "    return (x.min(), x.max())\n",
    "\n",
    "print(\n",
    "    get_count_range(all_records_df.groupby('tangram_id').size())\n",
    ")\n",
    "\n",
    "print(\n",
    "    get_count_range(all_records_df.groupby('scene').size())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tangram_distribution = []\n",
    "\n",
    "for t in pd.unique(all_records_df.tangram_id):\n",
    "    t_df = all_records_df.loc[all_records_df.tangram_id == t]\n",
    "    \n",
    "    n_entries = len(t_df)\n",
    "    n_workspaces = len(pd.unique(t_df.workspace_name))\n",
    "    n_scenes = len(pd.unique(t_df.scene))\n",
    "    \n",
    "    tangram_distribution.append({\n",
    "        'tangram_id': t, 'n_entries': n_entries, 'n_workspaces': n_workspaces, 'n_scenes': n_scenes,\n",
    "    })\n",
    "\n",
    "tangram_distribution_df = pd.DataFrame(tangram_distribution)\n",
    "tangram_distribution_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tangrams_scenes_in_workspaces = []\n",
    "\n",
    "for ws in pd.unique(all_records_df.workspace_name):\n",
    "    ws_df = all_records_df.loc[all_records_df.workspace_name == ws]\n",
    "    \n",
    "    n_entries = len(ws_df)\n",
    "    n_tangrams = len(pd.unique(ws_df.tangram_id))\n",
    "    n_scenes = len(pd.unique(ws_df.scene))\n",
    "    \n",
    "    tangram_counts_range =  get_count_range(ws_df.groupby('tangram_id').size())\n",
    "    scene_counts_range =  get_count_range(ws_df.groupby('scene').size())\n",
    "    \n",
    "    tangrams_scenes_in_workspaces.append({\n",
    "        'workspace': ws, 'n_entries': n_entries, 'n_tangrams': n_tangrams, 'n_scenes': n_scenes, 'tangram_counts_range': tangram_counts_range, 'scene_counts_range': scene_counts_range\n",
    "    })\n",
    "    \n",
    "pd.DataFrame(tangrams_scenes_in_workspaces).set_index('workspace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "argilla",
   "language": "python",
   "name": "argilla"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
