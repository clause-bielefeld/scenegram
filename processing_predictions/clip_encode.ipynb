{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from tqdm.auto import tqdm\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_path = osp.abspath('../analyzing_annotations/clip_model')\n",
    "model_id = 'openai/clip-vit-base-patch32'\n",
    "\n",
    "model = CLIPModel.from_pretrained(model_id, cache_dir=clip_path)\n",
    "print('model: success')\n",
    "processor = CLIPProcessor.from_pretrained(model_id, cache_dir=clip_path)\n",
    "print('processor: success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_features(s, clip_model=model, clip_processor=processor, return_numpy=True):\n",
    "    max_length = clip_processor.tokenizer.max_model_input_sizes[clip_processor.tokenizer.name_or_path]\n",
    "    inputs = clip_processor(text=s, return_tensors='pt', truncation=True, max_length=max_length)\n",
    "    outputs = clip_model.get_text_features(**inputs).squeeze()\n",
    "    return outputs.detach().numpy() if return_numpy else outputs\n",
    "\n",
    "def get_mean_text_features(responses):\n",
    "    if type(responses) == str:\n",
    "        responses = eval(responses)\n",
    "    features = list(map(get_text_features, responses))\n",
    "    mean_features = np.vstack(features).mean(axis=0)\n",
    "    return mean_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twostep_predictions = True\n",
    "fewshot_predictions = False\n",
    "\n",
    "processed_dir = osp.abspath('../predicted_data/processed')\n",
    "input_file = osp.join(processed_dir, f'processed_predictions{\"_twostep\" if twostep_predictions else \"\"}{\"_fewshot\" if fewshot_predictions else \"\"}.csv')\n",
    "\n",
    "output_dir = osp.join(processed_dir, 'clip_encodings')\n",
    "if not osp.isdir(output_dir):\n",
    "    print(f'make directory {output_dir}')\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "pred_df = pd.read_csv(input_file, index_col=0)\n",
    "\n",
    "response_cols = [c for c in pred_df.columns if c.startswith('response_')]\n",
    "models = [c.replace('response_', '') for c in response_cols]\n",
    "\n",
    "tangrams = sorted(pd.unique(pred_df.tangram))\n",
    "scenes = sorted(pd.unique(pred_df.scene))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_array = pred_df.item_identifyer.values\n",
    "\n",
    "results = dict()\n",
    "cols = ['response', 'label']\n",
    "\n",
    "for model, rl in tqdm(list(product(models, cols))):\n",
    "    col=f'{rl}_{model}'\n",
    "    embeds = pred_df[col].map(get_text_features)\n",
    "    results[col] = np.stack(embeds.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = osp.join(output_dir, osp.splitext(input_file)[0] + '_embeddings.npz')\n",
    "print(outfile)\n",
    "np.savez(outfile, text_idx=idx_array, **results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "context_representations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
