{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "\n",
    "import gensim.downloader as api\n",
    "\n",
    "def replace_invalid_with_nan(vector):\n",
    "    return np.where(vector==0.0, np.nan, vector)\n",
    "\n",
    "def glove_vector(words, wv):\n",
    "    return wv.get_mean_vector(words)\n",
    "\n",
    "def add_cn_prefix(word):\n",
    "    return f'/c/en/{word}'\n",
    "\n",
    "def cn_vector(words, wv):\n",
    "    if len(words) > 1:\n",
    "        compound = add_cn_prefix('_'.join(words))\n",
    "        if wv.__contains__(compound):\n",
    "            return wv.get_mean_vector([compound])\n",
    "    return wv.get_mean_vector([add_cn_prefix(word) for word in words])\n",
    "    \n",
    "def get_static_embed(word, wv, mode):\n",
    "    \n",
    "    if type(word) != str:\n",
    "        # fallback for e.g. None inputs\n",
    "        return np.full([wv.vector_size], np.nan)\n",
    "    \n",
    "    words = word.split()\n",
    "    if mode=='glove':\n",
    "        vector = glove_vector(words, wv)\n",
    "    elif mode=='cn':\n",
    "        vector = cn_vector(words, wv)\n",
    "    \n",
    "    if all(vector == 0.0):\n",
    "        return replace_invalid_with_nan(vector)\n",
    "    return vector\n",
    "\n",
    "def unpack_anns(list_of_annotations):\n",
    "    return [(i, x['whole']['wholeAnnotation']) for i, x in enumerate(list_of_annotations)]\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twostep_predictions = True\n",
    "fewshot_predictions = False\n",
    "\n",
    "processed_dir = osp.abspath('../predicted_data/processed')\n",
    "input_file = osp.join(processed_dir, f'processed_predictions{\"_twostep\" if twostep_predictions else \"\"}{\"_fewshot\" if fewshot_predictions else \"\"}.csv')\n",
    "\n",
    "output_dir = osp.join(processed_dir, 'static_encodings')\n",
    "if not osp.isdir(output_dir):\n",
    "    print(f'make directory {output_dir}')\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "pred_df = pd.read_csv(input_file, index_col=0)\n",
    "\n",
    "response_cols = [c for c in pred_df.columns if c.startswith('response_')]\n",
    "models = [c.replace('response_', '') for c in response_cols]\n",
    "\n",
    "tangrams = sorted(pd.unique(pred_df.tangram))\n",
    "scenes = sorted(pd.unique(pred_df.scene))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leave out raw and clean anns\n",
    "\n",
    "idx_array = pred_df.item_identifyer.values\n",
    "cols = ['response', 'label']\n",
    "\n",
    "for emb_model, emb_model_name in [\n",
    "        ('glove-wiki-gigaword-300', 'glove'),\n",
    "        ('conceptnet-numberbatch-17-06-300', 'cn')\n",
    "    ]:\n",
    "    \n",
    "    print(f'load embeddings for {emb_model_name} / {emb_model}')\n",
    "    word_vectors = api.load(emb_model)\n",
    "    def get_embeddings(word):\n",
    "        return get_static_embed(word, wv=word_vectors, mode=emb_model_name)\n",
    "\n",
    "    results = dict()\n",
    "\n",
    "    for model, rl in tqdm(list(product(models, cols))):\n",
    "        col=f'{rl}_{model}'\n",
    "        print(f'calculate embeddings for {col}')\n",
    "    \n",
    "        embeds = pred_df[col].map(get_embeddings)\n",
    "        results[col] = np.stack(embeds.to_list())\n",
    "\n",
    "    outfile = osp.join(output_dir, f'{osp.splitext(input_file)[0]}_{emb_model_name}_embeddings.npz')\n",
    "    print(outfile)\n",
    "    np.savez(outfile, text_idx=idx_array, **results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gensim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
